# -*- coding: utf-8 -*-
"""AmazonPolarity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkbt1C2iiiXQdpa_tUCdigXjoBoGAK-d
"""

import pandas as pd
from datasets import load_dataset

# Load and preprocess dataset
dataset = load_dataset("amazon_polarity")

def preprocess(example):
    example['text'] = example['title'] + " " + example['content']
    return example

dataset = dataset.map(preprocess)

# Convert to DataFrames
df_train_full = pd.DataFrame(dataset['train'])
df_test_full = pd.DataFrame(dataset['test'])

# Combine and shuffle 100k from both train/test
df_combined = pd.concat([df_train_full, df_test_full], ignore_index=True)
df_sampled = df_combined.sample(n=100000, random_state=42).reset_index(drop=True)

# Split: 80k train, 20k test
df_train = df_sampled.iloc[:80000]
df_test = df_sampled.iloc[80000:]

# Final inputs
X_train = df_train['title'] + " " + df_train['content']
y_train = df_train['label']
X_test = df_test['title'] + " " + df_test['content']
y_test = df_test['label']

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

model = LogisticRegression(max_iter=300, solver='saga', n_jobs=-1)
model.fit(X_train_vec, y_train)

y_pred_lr = model.predict(X_test_vec)
print("Logistic Regression (Balanced Random Sample)")
print(classification_report(y_test, y_pred_lr, target_names=["Negative", "Positive"]))

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report

nb = MultinomialNB()
nb.fit(X_train_vec, y_train)
y_pred_nb = nb.predict(X_test_vec)

print("Multinomial Naive Bayes")
print(classification_report(y_test, y_pred_nb, target_names=["Negative", "Positive"]))

from sklearn.svm import LinearSVC

svm = LinearSVC()
svm.fit(X_train_vec, y_train)
y_pred_svm = svm.predict(X_test_vec)

print("Linear SVM")
print(classification_report(y_test, y_pred_svm, target_names=["Negative", "Positive"]))

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)
knn.fit(X_train_vec, y_train)
y_pred_knn = knn.predict(X_test_vec)

print("k-NN (k=10)")
print(classification_report(y_test, y_pred_knn, target_names=["Negative", "Positive"]))

"""Undersampling

"""

# Separate classes
df_class0 = df_train[df_train['label'] == 0]
df_class1 = df_train[df_train['label'] == 1]

# Downsample class 0 to 20% of its original size
df_class0_down = df_class0.sample(frac=0.2, random_state=42)

# Combine and shuffle
df_imbalanced = pd.concat([df_class0_down, df_class1]).sample(frac=1.0, random_state=42)

# Confirm new distribution
print("New label distribution:\n", df_imbalanced['label'].value_counts())

X_imb = vectorizer.fit_transform(df_imbalanced['text'])
y_imb = df_imbalanced['label']

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

lr_imb = LogisticRegression(max_iter=300, solver='saga', n_jobs=-1)
lr_imb.fit(X_imb, y_imb)

y_pred_lr_imb = lr_imb.predict(X_test_vec)
print("Logistic Regression (Imbalanced)")
print(classification_report(y_test, y_pred_lr_imb, target_names=["Negative", "Positive"]))

from sklearn.naive_bayes import MultinomialNB

nb_imb = MultinomialNB()
nb_imb.fit(X_imb, y_imb)

y_pred_nb_imb = nb_imb.predict(X_test_vec)
print("Naive Bayes (Imbalanced)")
print(classification_report(y_test, y_pred_nb_imb, target_names=["Negative", "Positive"]))

from sklearn.svm import LinearSVC

svm_imb = LinearSVC()
svm_imb.fit(X_imb, y_imb)

y_pred_svm_imb = svm_imb.predict(X_test_vec)
print("Linear SVM (Imbalanced)")
print(classification_report(y_test, y_pred_svm_imb, target_names=["Negative", "Positive"]))

from sklearn.neighbors import KNeighborsClassifier

knn_imb = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)
knn_imb.fit(X_imb, y_imb)

y_pred_knn_imb = knn_imb.predict(X_test_vec)
print("k-NN (Imbalanced)")
print(classification_report(y_test, y_pred_knn_imb, target_names=["Negative", "Positive"]))

"""Oversampling"""

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_ros, y_ros = ros.fit_resample(X_imb, y_imb)

# Check new label distribution
from collections import Counter
print("After oversampling:", Counter(y_ros))

# Oversample class 0 to match size of class 1
df_class0_oversampled = df_class0.sample(n=len(df_class1), replace=True, random_state=42)

# Combine and shuffle
df_oversampled = pd.concat([df_class0_oversampled, df_class1]).sample(frac=1.0, random_state=42)

# Confirm distribution
print("Oversampled label distribution:\n", df_oversampled['label'].value_counts())

lr_ros = LogisticRegression(max_iter=300, solver='saga', n_jobs=-1)
lr_ros.fit(X_ros, y_ros)
y_pred_lr_ros = lr_ros.predict(X_test_vec)
print("Logistic Regression (Oversampled)")
print(classification_report(y_test, y_pred_lr_ros, target_names=["Negative", "Positive"]))

nb_ros = MultinomialNB()
nb_ros.fit(X_ros, y_ros)
y_pred_nb_ros = nb_ros.predict(X_test_vec)
print("Naive Bayes (Oversampled)")
print(classification_report(y_test, y_pred_nb_ros, target_names=["Negative", "Positive"]))

svm_ros = LinearSVC()
svm_ros.fit(X_ros, y_ros)
y_pred_svm_ros = svm_ros.predict(X_test_vec)
print("Linear SVM (Oversampled)")
print(classification_report(y_test, y_pred_svm_ros, target_names=["Negative", "Positive"]))

knn_ros = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)
knn_ros.fit(X_ros, y_ros)
y_pred_knn_ros = knn_ros.predict(X_test_vec)
print("k-NN (Oversampled)")
print(classification_report(y_test, y_pred_knn_ros, target_names=["Negative", "Positive"]))

"""Class Weight = Balanced"""

from sklearn.svm import LinearSVC

svm_cw = LinearSVC(class_weight='balanced')
svm_cw.fit(X_train_vec, y_train)
y_pred_svm_cw = svm_cw.predict(X_test_vec)

print("Linear SVM (class_weight='balanced')")
print(classification_report(y_test, y_pred_svm_cw, target_names=["Negative", "Positive"]))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

lr_cw = LogisticRegression(
    max_iter=300,
    solver='saga',
    n_jobs=-1,
    class_weight='balanced'
)
lr_cw.fit(X_train_vec, y_train)
y_pred_lr_cw = lr_cw.predict(X_test_vec)

print("Logistic Regression (class_weight='balanced')")
print(classification_report(y_test, y_pred_lr_cw, target_names=["Negative", "Positive"]))

"""Visualization"""

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import classification_report

# Simulate results â€” replace these with your real y_pred and y_test
# For each strategy, store the predicted labels
results = {
    ('LogReg', 'Original'): y_pred_lr,
    ('LogReg', 'Undersampled'): y_pred_lr_imb,
    ('LogReg', 'Oversampled'): y_pred_lr_ros,
    ('LogReg', 'ClassWeight'): y_pred_lr_cw,
    ('NaiveBayes', 'Original'): y_pred_nb,
    ('NaiveBayes', 'Undersampled'): y_pred_nb_imb,
    ('NaiveBayes', 'Oversampled'): y_pred_nb_ros,
    ('SVM', 'Original'): y_pred_svm,
    ('SVM', 'Undersampled'): y_pred_svm_imb,
    ('SVM', 'Oversampled'): y_pred_svm_ros,
    ('SVM', 'ClassWeight'): y_pred_svm_cw,
    ('k-NN', 'Original'): y_pred_knn,
    ('k-NN', 'Undersampled'): y_pred_knn_imb,
    ('k-NN', 'Oversampled'): y_pred_knn_ros,
}

# Compute accuracy for each
data = []
for (model, strategy), y_pred in results.items():
    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
    accuracy = report['accuracy']
    data.append({'Model': model, 'Strategy': strategy, 'Accuracy': accuracy})

df = pd.DataFrame(data)

# Plot
plt.figure(figsize=(12, 6))
for model in df['Model'].unique():
    subset = df[df['Model'] == model]
    plt.plot(subset['Strategy'], subset['Accuracy'], marker='o', label=model)

plt.title("Accuracy Comparison by Model and Strategy")
plt.xlabel("Training Strategy")
plt.ylabel("Accuracy")
plt.ylim(0.35, 0.95)
plt.grid(True)
plt.legend(title="Model")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Extract counts
counts = {
    "Original": df_train['label'].value_counts().sort_index(),
    "Undersampled": df_imbalanced['label'].value_counts().sort_index(),
    "Oversampled": df_oversampled['label'].value_counts().sort_index(),
    "Balanced": df_train['label'].value_counts().sort_index()
}

# Combine into DataFrame
df_counts = pd.DataFrame(counts).T
df_counts.columns = ['Class 0', 'Class 1']  # ensure column names
df_counts = df_counts.fillna(0).astype(int)  # handle any missing classes

# Plot
df_counts.plot(kind='bar', figsize=(10, 6), rot=0)

plt.title("Class Distribution by Sampling Strategy")
plt.xlabel("Sampling Strategy")
plt.ylabel("Number of Samples")
plt.legend(title="Class")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Define model predictions (replace with your actual ones)
model_outputs = {
    "Logistic Regression": y_pred_lr,
    "Naive Bayes": y_pred_nb,
    "Linear SVM": y_pred_svm,
    "k-NN": y_pred_knn
}

# Plot heatmaps
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for ax, (model_name, y_pred) in zip(axes, model_outputs.items()):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                xticklabels=['Pred 0', 'Pred 1'],
                yticklabels=['True 0', 'True 1'])
    ax.set_title(f"{model_name}")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# UNDERSAMPLED
undersampled_outputs = {
    "LogReg (Undersampled)": y_pred_lr_imb,
    "NaiveBayes (Undersampled)": y_pred_nb_imb,
    "SVM (Undersampled)": y_pred_svm_imb,
    "k-NN (Undersampled)": y_pred_knn_imb
}

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for ax, (model_name, y_pred) in zip(axes, undersampled_outputs.items()):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=ax,
                xticklabels=['Pred 0', 'Pred 1'],
                yticklabels=['True 0', 'True 1'])
    ax.set_title(model_name)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.suptitle("Confusion Matrices: Undersampled Training", fontsize=16, y=1.02)
plt.tight_layout()
plt.show()

# OVERSAMPLED
oversampled_outputs = {
    "LogReg (Oversampled)": y_pred_lr_ros,
    "NaiveBayes (Oversampled)": y_pred_nb_ros,
    "SVM (Oversampled)": y_pred_svm_ros,
    "k-NN (Oversampled)": y_pred_knn_ros
}

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for ax, (model_name, y_pred) in zip(axes, oversampled_outputs.items()):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=ax,
                xticklabels=['Pred 0', 'Pred 1'],
                yticklabels=['True 0', 'True 1'])
    ax.set_title(model_name)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.suptitle("Confusion Matrices: Oversampled Training", fontsize=16, y=1.02)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# CLASS-WEIGHTED MODELS
class_weight_outputs = {
    "LogReg (Class Weight)": y_pred_lr_cw,
    "SVM (Class Weight)": y_pred_svm_cw
}

fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # 1 row, 2 plots
axes = axes.flatten()

for ax, (model_name, y_pred) in zip(axes, class_weight_outputs.items()):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', ax=ax,
                xticklabels=['Pred 0', 'Pred 1'],
                yticklabels=['True 0', 'True 1'])
    ax.set_title(model_name)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.suptitle("Confusion Matrices: Class-Weighted Models", fontsize=14, y=1.05)
plt.tight_layout()
plt.show()

